{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Techniques de Web Scraping avec Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titre</th>\n",
       "      <th>Annee_sortie_SC</th>\n",
       "      <th>Note_SC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Titre, Annee_sortie_SC, Note_SC]\n",
       "Index: []"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###   Web scraping avec le package BeautifulSoup\n",
    "\n",
    "\n",
    "#HTML -> BeautifulSoup \n",
    "#JavaScript (contenu dynamique ) -> Selenium\n",
    "\n",
    "#en bas de la page il y a un plusieur balises pour exemple\n",
    "\n",
    "from urllib.request import urlopen  # request permet de récupérer un site web\n",
    "from bs4 import BeautifulSoup # bs4 converti un site web en objet BeautifulSoup\n",
    "import pandas\n",
    "\n",
    "# fonction urlopen pour récupérer le code HTML de la page web\n",
    "page_SC = urlopen(\"https://www.senscritique.com/films/tops/top111\")\n",
    "\n",
    "#On crée une instance soup de la classe BeautifulSoup pour décrypter ce code HTML\n",
    "soup = BeautifulSoup(page_SC, 'html.parser')\n",
    "\n",
    "\n",
    "titre_SC = [] # On crée une liste vide qui contiendra tous les titres propres\n",
    "\n",
    "for element in soup.findAll(name = 'a', attrs = {'class': 'elco-anchor'}):\n",
    "    titre_SC.append(element.text)\n",
    "    \n",
    "print(titre_SC)\n",
    "\n",
    "annee_sortie_SC = []\n",
    "for element in soup.findAll('span', attrs={'class': 'elco-date'}):\n",
    "    annee_sortie_SC.append(element.text.strip(\"()\")) # On retire les parenthèses\n",
    "\n",
    "note_SC = []\n",
    "for element in soup.findAll('a', attrs={'class': 'erra-global'}):\n",
    "    note_SC.append(element.text.strip()) # On retire les espaces inutiles\n",
    "    \n",
    "# Création de la data frame\n",
    "\n",
    "sens_critique = pandas.DataFrame(list(zip(titre_SC,annee_sortie_SC,note_SC)), columns=[\"Titre\",\"Annee_sortie_SC\",\"Note_SC\"])\n",
    "\n",
    "sens_critique.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titre</th>\n",
       "      <th>Annee_sortie_imdb</th>\n",
       "      <th>Note_imdb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Les évadés</td>\n",
       "      <td>1994</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Le parrain</td>\n",
       "      <td>1972</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Le parrain, 2ème partie</td>\n",
       "      <td>1974</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Dark Knight: Le chevalier noir</td>\n",
       "      <td>2008</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 hommes en colère</td>\n",
       "      <td>1957</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Titre Annee_sortie_imdb Note_imdb\n",
       "0                          Les évadés              1994       8.9\n",
       "1                          Le parrain              1972       8.9\n",
       "2             Le parrain, 2ème partie              1974       8.9\n",
       "3  The Dark Knight: Le chevalier noir              2008       8.8\n",
       "4                 12 hommes en colère              1957       8.8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_imdb = urlopen(\"https://www.imdb.com/chart/top\")\n",
    "\n",
    "soup = BeautifulSoup(page_imdb, 'html.parser')\n",
    "\n",
    "titre_imdb = []\n",
    "for element in soup.select(\".titleColumn a\"):\n",
    "    titre_imdb.append(element.text)\n",
    "    \n",
    "annee_sortie_imdb = []\n",
    "for element in soup.findAll(name = 'span', attrs = {'class': 'secondaryInfo'}):\n",
    "    annee_sortie_imdb.append(element.text.strip(\"()\"))\n",
    "    \n",
    "note_imdb = []\n",
    "for element in soup.findAll(name = 'strong'):\n",
    "    note_imdb.append(element.text)\n",
    "    \n",
    "note_imdb = note_imdb[4:]\n",
    "\n",
    "# Création de la data frame\n",
    "\n",
    "imdb = pandas.DataFrame(list(zip(titre_imdb,annee_sortie_imdb,note_imdb)), columns=[\"Titre\",\"Annee_sortie_imdb\",\"Note_imdb\"])\n",
    "\n",
    "imdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# Retirer les accents de la colonne \"Titre\"\n",
    "\n",
    "imdb[\"Titre\"] = imdb[\"Titre\"].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "sens_critique[\"Titre\"] = sens_critique[\"Titre\"].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "\n",
    "# Mettre tout en majuscule\n",
    "\n",
    "imdb[\"Titre\"] = imdb[\"Titre\"].str.upper()\n",
    "sens_critique[\"Titre\"] = sens_critique[\"Titre\"].str.upper()\n",
    "\n",
    "# Merge\n",
    "\n",
    "note_finale = imdb.merge(sens_critique, how = \"inner\", left_on = \"Titre\", right_on = \"Titre\", )\n",
    "\n",
    "note_finale[\"Note_imdb\"] = pandas.to_numeric(note_finale[\"Note_imdb\"])\n",
    "note_finale[\"Note_SC\"] = pandas.to_numeric(note_finale[\"Note_SC\"])\n",
    "\n",
    "# T-test\n",
    "\n",
    "ttest_rel(note_finale[\"Note_imdb\"],note_finale[\"Note_SC\"])\n",
    "\n",
    "# La p-value du test de Student est inférieure à 0,05, on rejette donc l'hypothèse que les \n",
    "# moyennes sont égales. Comme la statistique de test est positive, la différence entre la moyenne \n",
    "# IMDB et la moyenne Sens Critique est elle aussi positive, ce qui suggère que les utilisateurs \n",
    "# IMDB sont plus cléments que les utilisateurs Sens Critique quant à la notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://datascientest.com/parite-en-intelligence-artificielle-un-enjeu-cle\n",
      "https://www.actuia.com/tag/parite/\n",
      "https://www.laboratoiredelegalite.org/le-pacte-pour-une-intelligence-artificielle-egalitaire-entre-les-femmes-et-les-hommes/\n",
      "https://www.lesechos.fr/idees-debats/cercle/opinion-pas-de-diversite-des-genres-sans-intelligence-artificielle-256956\n",
      "https://www.nextinpact.com/article/28220/106379-ia-ethique-boites-noires-parite-et-armes-autonomes-dans-rapport-cedric-villani\n",
      "https://itsocial.fr/enjeux-it/enjeux-strategie/enjeu-digital/parite-homme-femme-lit-vision-dexakis-nelite/\n",
      "https://digital-society-forum.orange.com/fr/les-actus/1195-les-biais-sexistes-de-l39intelligence-artificielle\n",
      "https://redpill.nospoon.fr/ia-lintelligence-artificielle-menace-t-elle-legalite-femmes-hommes/\n",
      "https://www.epsi.fr/femmes-et-intelligence-artificielle/\n",
      "https://www.unitheque.com/intelligence-artificielle-pas-sans-elles/egale-a%C2%A0-egal/belin/Livre/138853\n",
      "https://www.belin-editeur.com/lintelligence-artificielle-pas-sans-elles\n"
     ]
    }
   ],
   "source": [
    "# Web Scraper les requêtes Google\n",
    "#Web Scraping avec le package GoogleSearch\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from googlesearch import search   #Importez la fonction search du module googleSearch\n",
    "\n",
    "\n",
    "#Cherchez 10 premiers articles sur google concernant la parité en intelligence \n",
    "#artificielle en francais demandant une pause de 2s entre chaque requêtes\n",
    "\n",
    "for url in search('parite en intelligence artificielle', \n",
    "                  tld='com', lang='fr',\n",
    "                  num= 10, pause= 2.0):\n",
    "    print (url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=“http://wikipedia.org”>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'newspaper'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-291bd8458595>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Web Scraping avec le package NewsPaper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnewspaper\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mArticle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://datascientest.com/parite-en-intelligence-artificielle-un-enjeu-cle'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0marticle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mArticle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'newspaper'"
     ]
    }
   ],
   "source": [
    "#Web Scraping avec le package NewsPaper    \n",
    "\n",
    "from newspaper import Article\n",
    "url = 'https://datascientest.com/parite-en-intelligence-artificielle-un-enjeu-cle'\n",
    "article = Article(url)\n",
    "article.download()\n",
    "article.parse()\n",
    "print(article.text)   #recupere tout \n",
    "\n",
    "\n",
    "\n",
    "print (article.nlp() ) # on fait avant tout fonctionner le langage naturel\n",
    "print (article.authors )\n",
    "print (article.publish_date)\n",
    "print (article.summary)\n",
    "print (article.keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction au web scripping\n",
    "\n",
    "https://www.youtube.com/watch?v=Fvl7wZRkplU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction au langage web\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Introduction à HTML\n",
    "\n",
    "Le HTML (HyperText Markup Language) est un langage de balisage\n",
    "\n",
    " - Les balises en paires : Elles s'ouvrent, contiennent du texte, et se referment. < titre>Ceci est un titre< /titre>\n",
    "\n",
    " - Les balises orpheline : Ce sont des balises qui servent à insérer un élément à un endroit précis (par exemple une image, un lien). Il n'est pas nécessaire de délimiter le début et la fin.Une balise orpheline s'écrit comme ceci : <image/>\n",
    "\n",
    " - Les attributs : Les attributs viennent compléter les balises afin de donner des informations supplémentaires. L'attribut se place après le nom de la balise ouvrante et a le plus souvent une valeur, comme ceci :< balise attribut=\"valeur\"> Par exemple, dans une balise orpheline insérant une image, on ajoute généralement un attribut qui indique le nom de l'image à afficher < image nom=\"photo.jpg\" />\n",
    " \n",
    "Le modele type : \n",
    "\n",
    " - Le Doctype <!DOCTYPE html>: une page HTML démarre toujours en précisant le doctype de notre document.\n",
    "\n",
    " - L'élément HTML: composé d’une paire de balises ouvrante < html> et fermante < /html>. L’élément html va représenter notre page, on y insérera tout le contenu de notre page à l’intérieur de celui-ci.\n",
    "    \n",
    " - L'élément head :< head> est un élément d’en-tête. Il va contenir des éléments qui vont servir à fournir des informations sur la page au navigateur, comme le titre de la page.\n",
    "    \n",
    " - L'élément body : < body> contiendra les éléments définissant les contenus de la page à destination de l’utilisateur comme les différents textes présents dans la page, les images, etc.\n",
    "    \n",
    " - L'élément title : < title> va nous permettre d’indiquer le titre de la page visible sur le haut des onglets de votre navigateur, par exemple ici on aurait < title> DataScienTest - Train </ title>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Introduction à CSS\n",
    "\n",
    "\n",
    " - L'attribut .classe\n",
    "vous devez écrire un nom qui sert à identifier la balise\n",
    "\n",
    "\n",
    "- L'attribut #ID\n",
    "L'attribut #id fonctionne de la même manière que .class à un détail près : il ne peut être utilisé qu'une fois dans le code\n",
    "\n",
    "\n",
    "https://www.youtube.com/watch?v=Fvl7wZRkplU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balises\tRôle\n",
    "<html>...</html>\tEncadre tout le code HTML (balise principale)\n",
    "<head>...</head>\tEn tête de la page\n",
    "<body>...</body>\tCorps de la page\n",
    "<h1> <h2>...<h6>\tTitres\n",
    "<img src=\"lien\" />\tImage\n",
    "<a href=\"lien\"> </a>\tLien hypertexte\n",
    "<p>...</p>\tParagraphe\n",
    "<ul>...</ul>\tListe à puces (non numérotée)\n",
    "<ol>...</ol>\tListe à puces (numérotée)\n",
    "<li>...</li>\tEléments de liste à puces\n",
    "<table>...</table>\tTable\n",
    "<tbody>...</tbody>\tCorps d'une table (regroupe une ou plusieurs balises <tr>)\n",
    "<tr>...</tr>\tLigne d'une table\n",
    "<td>...</td>\tCellule d'une table\n",
    "<div>...</div>\tDivision du contenu (prend un sens lorsqu'elle est associée à un attribut)\n",
    "<script>...</script>\tCode JavaScript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Quel sélecteur css est utilisée afin de définir le style d’un seule élément?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('id')\n",
    "#print('text')\n",
    "#print('class')\n",
    "#print('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Quel est la balise HTML correcte pour un grand titre ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('H1')\n",
    "#print('Heading')\n",
    "#print('Head')\n",
    "#print('H6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Quelle balise est utilisée pour lister les éléments avec des puces ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('<puce>…</puce>')\n",
    "#print('<list>…</list>')\n",
    "print('<ul>…</ul>')\n",
    "#print('<ol>…</ol>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Quelle est la syntaxe correcte du code CSS suivant ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Body:color=black')\n",
    "#print('{body;color:black}')\n",
    "#print('{body:color=black(body}')\n",
    "print('Body {color: Black}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lequel des attributs est obligatoire dans la balise <img>?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('src')\n",
    "#print('href')\n",
    "#print('id')\n",
    "#print('alt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Quel est la bonne syntaxe afin de créer un lien vers la page d’accueil de Wikipédia ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('<a target=“http://wikipedia.org”>Wikipédia</a>')\n",
    "#print('<a href=“http://wikipedia.org”>')\n",
    "print('<a href=“http://wikipedia.org”>Wikipédia</a>')\n",
    "#print('<a target=“http://wikipedia.org”>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Laquelle de ces syntaxes est correcte ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('<img>src=“mon-image.jpg” alt=“Une image”</img>')\n",
    "#print('<img src=“mon-image.jpg” alt=“Une image”>')\n",
    "#print('<img href=“mon-image.jpg” alt=“Une image”>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Partie 2: Web Scraping avec Beautiful Soup¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Importez les module pandas , beautiful soup et urllopen\n",
    "Afficher l'ensemble des titres de films contenus dans la liste Title sur la page mentionnée plus haut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen  # request permet de récupérer un site web\n",
    "from bs4 import BeautifulSoup # bs4 converti un site web en objet BeautifulSoup\n",
    "import pandas\n",
    "\n",
    "\n",
    "page = urlopen(\"https://www.rottentomatoes.com/top/bestofrt/top_100_action__adventure_movies/\")\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "\n",
    "titre = [] # On crée une liste vide qui contiendra tous les titres propres\n",
    "\n",
    "\n",
    "for element in soup.findAll(attrs = {'class': 'unstyled articleLink'}):\n",
    "    titre.append(element.text.strip('\\n xa'))    \n",
    "    \n",
    "titre = titre [43:143]\n",
    "titre[:5]\n",
    "len (titre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "De la même manière que ci-dessus, créez les listes num_critique_SC et note_SC contenant respectivement le nombre de critiques et la note de chaque film de la liste.\n",
    "Utilisez la méthode strip() pour \"nettoyer\" les listes obtenues précédemment (supprimer les parenthèses : \"()\" et les espaces inutiles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = [] \n",
    "\n",
    "for element in soup.findAll(name = 'span' ,  attrs = {'class': 'tMeterScore'}):\n",
    "    rating.append(element.text.strip('\\n'))\n",
    "    \n",
    "rating = rating[20:120]\n",
    "\n",
    "\n",
    "\n",
    "cmt = [] \n",
    "for element in soup.findAll(attrs = {'class': 'right hidden-xs'}):\n",
    "    cmt.append(element.text.strip(''))\n",
    "    \n",
    "cmt = cmt[1:101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Créer un dataframe nommérotten_tomatoes qui contient ces trois listes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code\n",
    "rotten_tomatoes   = pandas.DataFrame (list(zip(titre,rating,cmt)), columns= [\"titre\",\"rating\",\"Comment\"])\n",
    "\n",
    "rotten_tomatoes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Partie 3: Web Scraping GoogleSearch/NewsPaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Importez la fonction search du module GoogleSearch\n",
    "Cherchez 20 premiers articles sur google concernant la data science en anglais demandant une pause de 2s entre chaque requêtes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googlesearch import search   #Importez la fonction search du module googleSearch\n",
    "\n",
    "\n",
    "for url in search('data science', \n",
    "                  tld='com', lang='en',\n",
    "                  num= 20, pause= 2.0):\n",
    "    print (url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reprenez le lien qui reviens en premier c'est à dire celui ci\n",
    "\n",
    "Importez la fonction Article du module Newspaper.\n",
    "Saisissez l'url de l'article puis telecharger le afin d'acceder au contenu.\n",
    "Affichez l'article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "url = 'https://www.kainos.com/my-experience-as-a-data-scientist'\n",
    "article = Article(url)\n",
    "article.download()\n",
    "article.parse()\n",
    "print(article.text)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (article.nlp() ) # on fait avant tout fonctionner le langage naturel\n",
    "print (article.authors )\n",
    "print (article.publish_date)\n",
    "print (article.summary)\n",
    "print (article.keywords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
