{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resume Partie 1 : Modèles de régression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------------------------------------------------------\n",
    "#1 - Récupération des données-------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------Import package\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#---------------------------------------------------------------------Import df\n",
    "df =pd.read_csv('file.csv') #import du df\n",
    "\n",
    "#df.columns = df['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
    "#           'PTRATI0', 'B', 'LSTAT','PRICE']\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------\n",
    "#2 - Prétraitement et Sélection des variables: -------------------------------------------------------------------------------\n",
    "\n",
    "X = df.drop('PRICE', axis=1) #Extraire dans un tableau X le data frame housing dépourvu de la variable PRICE\n",
    "Y = df['PRICE'] #Extraire dans un tableau Y la colonne PRICE de housing\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=5)\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------\n",
    "#3 - Choix du modèle ou prédicteur: ------------------------------------------------------------------------------------------\n",
    "\n",
    "#Importer la classe LinearRegression du sous module sklearn.linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#Créer un objet lm de type LinearRegression pour La création d'un modèle de régression linéaire\n",
    "lm = LinearRegression()\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------\n",
    "#4 - Entraînement du modèle: -------------------------------------------------------------------------------------------------\n",
    "\n",
    "lm.fit(X_train,Y_train) #le modèle lm crée, il doit être entraîné à partir des échantillons d'apprentissage\n",
    "\n",
    "#Le modèle ainsi entraîné a donc calculé des estimateurs pour l'intercept (l’ordonnée à l’origine) et \n",
    "#les coefficients de la formule de régression\n",
    "print(\"Intercept estimé : \", lm.intercept_)\n",
    "#Affiche un Dataframe contenant chacune des variables explicatives et son coefficient estimé par le modèle associé\n",
    "pd.DataFrame({'coefficients estimés': lm.coef_ }, index = X_train.columns)\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------\n",
    "#5 - Evaluation du modèle: ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------Partie 2 : Modèles de classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Cours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn est une bibliothèque libre de Python destinée à démocratiser le Machine Learning, qui ne nécessite pas ou peu de prérequis en apprentissage automatique. Elle présente une interface de qualité, simple d'utilisation et développée par une petite communauté de contributeurs très active et qui évolue rapidement. L’introduction de nouvelles méthodes dans scikit-learn est sous contrôle d’un petit groupe qui vérifie la pertinence des méthodes, seules celles reconnues sont acceptées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une documentation de ce package : https://scikit-learn.org/stable/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour mettre à l'oeuvre une méthode d'apprentissage supervisé, il convient souvent d'effectuer dans l'ordre les étapes suivantes:\n",
    "\n",
    "    1 - Récupération des données: Cette étape semble triviale mais fait partie de celles qui prennent le plus de temps.\n",
    "\n",
    "    2 - Prétraitement et Sélection des variables: Les données brutes sont souvent inexploitables telles qu'elles nous sont fournies. Elles doivent donc passer par quelques étapes de mise en forme, puis vient l'heure du choix des variables à utiliser pour décrire les données.\n",
    "\n",
    "    3 - Choix du modèle ou prédicteur: Comme pour la sélection des features, il n’y a pas de méthodes automatiques. Cela dépend en grande partie des données et de facteurs empiriques.\n",
    "\n",
    "    4 - Entraînement du modèle: Pour chaque modèle, il existe un algorithme d’entraînement. Cette étape prend souvent beaucoup de temps et augmente avec la taille des données d’entrée.\n",
    "\n",
    "    5 - Evaluation du modèle: Plusieurs méthodes existent pour évaluer un modèle. Les méthodes les plus courantes sont les méthodes dites d'échantillonnage, qui consistent à découper l’ensemble de données en plusieurs échantillons, d’entraîner le modèle sur une partie des échantillons et de tester le modèle sur l'autre partie. On calcule ensuite plusieurs indicateurs pour évaluer le modèle, en particulier son taux de bonnes prédictions pour une classification et le coefficient de détermination pour une régression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------Partie 1 : Modèles de régression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------------------------Import package\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#-----------------------------------------------------------------------------------------------Import df\n",
    "df =pd.read_csv('file.csv') #import du df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Apprentissage Supervisé la séparation des données en un échantillon d'apprentissage et un échantillon de test correspond à une partie importante de l'évaluation des modèles. En général, lorsque l'on construit un modèle à partir d'un jeu de données, une grande partie de ces données est utilisée pour l'apprentissage du modèle, et une plus petite est gardée pour le test des modèles.\n",
    "\n",
    "Le sous module model_selection de Scikit-learn contient la fonction train_test_split() qui permet de créer facilement à partir d'un jeu de données et d'un vecteur contenant la variable à prédire, un échantillon d'apprentissage et un échantillon test. \n",
    "La fonction contient principalement les paramètres suivants :\n",
    "\n",
    "    - arrays : Deux tableaux/vecteurs de même longueurs contenant respectivement les variables à utiliser pour l'apprentissage du modèle et la variable à prédire.\n",
    "    - test_size : La proportion de données à extraire dans l'échantillon de test.\n",
    "    - random_state : Nombre générateur de valeurs pseudo-aléatoires utilisé pour reproduire facilement l'échantillonnage aléatoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer la fonction train_test_split du sous module sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split  \n",
    "\n",
    "#Extraire dans un tableau X le data frame housing dépourvu de la variable PRICE\n",
    "X = housing.drop('PRICE', axis=1)\n",
    "Y = housing['PRICE']\n",
    "\n",
    "\n",
    "#Crée les df X_train, X_test, Y_train, Y_test à partir de X et Y en utilisant la fonction train_test_split et \n",
    "#en gardant 20% des données pour l'échantillon de test Par souci de reproductibilité des résultats, on utilise random_state=5.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La création d'un modèle de régression linéaire avec Scikit-learn s'effectue grâce la classe LinearRegression du sous module sklearn.linear_model.\n",
    "\n",
    "La première étape est d'instancier un objet de classe LinearRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importer la classe LinearRegression du sous module sklearn.linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#Créer un objet lm de type LinearRegression grâce à la commande lm = LinearRegression().\n",
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois le modèle lm crée, il doit être entraîné à partir des échantillons d'apprentissage. Sur Scikit-learn tous les modèles possèdent la même méthode pour être entraînés: fit( )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle ainsi entraîné a donc calculé des estimateurs pour l'intercept (l’ordonnée à l’origine) et les coefficients de la formule de régression. Il peuvent être respectivement obtenus via les attributs lm.intercept_ et lm.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Intercept estimé : \", lm.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Affiche un Dataframe contenant chacune des variables explicatives et son coefficient estimé par le modèle associé\n",
    "pd.DataFrame({'coefficients estimés': lm.coef_ }, index = X_train.columns)\n",
    "\n",
    "#out :  RM=3.413973\n",
    "\n",
    "#En observant le coefficient associé à la variable RM, \n",
    "#on peut constater que le nombre de pièces moyen par maison \n",
    "#a un impact positif sur le prix des habitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle construit doit maintenant être évalué en effectuant des prédictions sur l'échantillon de test. Comme pour la fonction fit(), sur Scikit-learn tous les modèles possèdent la même méthode pour effectuer des prédictions: predict\n",
    "\n",
    "Dans le cadre de la régression linéaire, la fonction predict utilisera les coefficients estimés, pour calculer les variables que l'on souhaite prédire à partir de l'échantillon test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Prédictions : \", lm.predict(X_test)[0:5])\n",
    "print(\"Valeurs réelles : \",  list(Y_test[0:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pour visualiser la justesse des prédictions\n",
    "plt.scatter(Y_test, lm.predict(X_test))\n",
    "x = np.linspace(5,50)\n",
    "plt.plot(x,x,'g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode lm.score permet de calculer le coefficient de détermination  R2R2  des prédictions.\n",
    "\n",
    "Le coefficient  R2R2  est compris entre 0 et 1, il permet de juger de la bonne adéquation entre le modèle et les données observées. Plus il se rapproche de 1 et plus le pouvoir prédictif du modèle est fort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lm.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est également possible de calculer l'erreur quadratique moyenne des prédictions, qui est un bon indicateur de comparaison entre deux modèles.\n",
    "Le sous module sklearn.metrics contient la fonction mean_squared_error permettant de calculer cette mesure.\n",
    "Plus elle est proche de 0, meilleures sont les prédictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(\"Erreur quadratique moyenne: \", mean_squared_error(Y_test, lm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A présent, en s'inspirant du code effectué pour la régression linéaire, essayons de construire un modèle identique au précédent, en utilisant une régression Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "rl = Lasso(alpha = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entraîne le modèle rl à partir de X_train et Y_train\n",
    "rl.fit(X_train,Y_train)  \n",
    "\n",
    "#Affiche un Dataframe contenant chacune des variables explicatives et son coefficient estimé par le modèle rl associé\n",
    "pd.DataFrame({'coefficients estimés': rl.coef_ }, index = X_train.columns)\n",
    "\n",
    "#Calcule les prédictions du modèle rl sur X_test et afficher les 5 premières\n",
    "#Compare avec les 5 premières valeurs de Y_test et les 5 premières valeurs prédites par le modèle lm\n",
    "print(\"Prédictions : \", rl.predict(X_test)[0:5])\n",
    "print(\"Prédictions : \", lm.predict(X_test)[0:5])\n",
    "print(\"Valeurs réelles : \",  list(Y_test[0:5]))\n",
    "\n",
    "#Affiche le coefficient de détermination des prédictions effectuées sur X_test, \n",
    "#ainsi que l'erreur quadratique moyenne des prédictions\n",
    "print(\"Coefficient de détermination: \", rl.score(X_test, Y_test)) \n",
    "print(\"Erreur quadratique : \", mean_squared_error(Y_test ,rl.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le coefficient de détermination obtenu pour ce modèle est moins élevé que celui du modèle de régression linéaire. Le modèle est moins bien ajusté.\n",
    "\n",
    "Aussi, l''erreur quadratique est plus élevée pour le modèle de régression Lasso, les prédictions sont donc moins bonnes que celles du premier modèle.\n",
    "\n",
    "Il est donc possible de conclure que, sur nos données, le modèle de régression linéaire est plus efficace que le modèle de régression Lasso construit ici.\n",
    "\n",
    "En revanche, les variables les plus importantes (celles avec les coefficients les plus élevées) sont relativement les mêmes, et notamment le nombre de pièces par maison qui, intuitivement est un facteur important dans le prix d'un logement.\n",
    "\n",
    "Bravo, vous avez découvert le principe de l'apprentissage supervisé, puis créé et évalué vos premiers modèles de prédiction au moyen de régressions.\n",
    "\n",
    "Dans la suite, vous créerez votre premier modèle de classification supervisée !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#--------------------------------------------------------------------Partie 2 : Modèles de classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette seconde partie, nous nous intéresserons au problème de classification supervisé.\n",
    "Pour rappel, on parle de classification lorsque l'ensemble des valeurs à prédire est fini.\n",
    "La fonction de prédiction est alors appelée un classifieur dont l'objectif est d'identifier la/les classes auxquelles appartiennent nos données observées à partir de traits descriptifs (variables ou features).\n",
    "Le terme 'supervisé' signifie que les classes sont connues pour nos observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import package #--------------------------------------------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#Import df #--------------------------------------------------------------------------------------------------------------\n",
    "df = pd.read_csv('votes.csv')\n",
    "\n",
    "#si replace var #----------------------------------------------------------------------------------------------------------\n",
    "#df.replace(['y','n'],[1,0],inplace= True)   #remplacer des val peut etre utile\n",
    "\n",
    "#Tracer une courbe #-------------------------------------------------------------------------------------------------------\n",
    "#Pour se faire une idée de la répartition des votes des différents représentants en fonction de leur parti, \n",
    "#un graphique peut s'avérer très utile.\n",
    "plt.figure()\n",
    "sns.countplot(x='education', hue='party', data=df, palette='RdBu')\n",
    "plt.xticks([0,1], ['No', 'Yes'])\n",
    "plt.show()\n",
    "\n",
    "#fonction train_test_split #------------------------------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.iloc[:, 1:] #toute col exepter la 1 \n",
    "Y = df.party\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=7)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaque algorithme d'apprentissage automatique possède sa propre classe pour construire un estimateur, mais tous s'utilisent de la même manière. Il n'est pas possible de savoir à l'avance quel algorithme sera le meilleur pour ce problème ou quels paramètres utiliser, il est donc préférable de créer plusieurs modèles et de comparer leurs résultats.\n",
    "\n",
    "Créeons en premier lieu un modèle basé sur l'algorithme des K Plus Poches voisins (K-Nearest Neighbors ), qui consiste globalement à classer une observation selon la classe des k autres observations les plus proches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier   #entrainement au modele\n",
    "knn =  KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois le modèle construit et entraîné, il est possible de prédire le résultat de l'estimation sur l'échantillon de test en utilisant la méthode predict afin de classer chaque membre de X_test dans un des deux partis du Congrès."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois le modèle construit et entraîné, il est possible de prédire le résultat de l'estimation sur l'échantillon de test en utilisant la méthode predict afin de classer chaque membre de X_test dans un des deux partis du Congrès."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions= knn.predict(X_test)\n",
    "predictions[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode score permet quant à elle de retourner directement le 'score' de performance du modèle.\n",
    "Par défaut ce score représente le taux de bonnes prédictions (accuracy) du modèle appliqué à un échantillon et aux valeurs réelles que le modèle est censé prédire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.score(X_test , Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour avoir plus de détails sur l'efficacité du modèle sur l'échantillon de test, la matrice de confusion est un excellent outil. Il s'agit d'une matrice dont chaque colonne représente le nombre de données prédites comme appartenant à une certaine classe, tandis que les ligne représentent le nombre d'occurrences dans les classes réelles.\n",
    "\n",
    "Un des intérêts de la matrice de confusion est qu'elle montre rapidement si un système de classification parvient à classer correctement de nouvelles données.\n",
    "Les éléments en dehors de la diagonale principale représentent les erreurs de prédiction, tandis que les éléments sur la diagoniale font référence aux bonnes prédictions.\n",
    "La fonction confusion_matrix du sous module sklearn.metrics permet d'afficher une matrice de confusion entre les valeurs réelles que l'on cherche à prédire et les prédictions faites par le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "print(confusion_matrix(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matrice qui s'affiche représente dans la première colonne les individus prédits démocrates, dans la seconde les individus prédits républicains. La première ligne représente les vrais démocrates, et la seconde les vrais républicains.\n",
    "\n",
    "Grâce à cette matrice il est possible de voir que seulement 5 représentants de la Chambre ont été mal classés. Quatre démocrates ont été classés républicains par le modèle, et un seul républicain a été classé démocrate.\n",
    "\n",
    "Le score utilisé ici pour évaluer notre modèle est le taux de bonnes prédictions, qui avoisine les 94%, mais ce n'est pas la seule métrique existante pour mesurer la pertinence du modèle. La fonction classification_report du sous module sklearn.metrics permet d'afficher plus de résultats quant à la performance du modèle, notamment la précision et le rappel et la F-Mesure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import  classification_report\n",
    "\n",
    "classification_report(Y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
