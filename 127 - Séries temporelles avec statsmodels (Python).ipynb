{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divers  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bande de bolinger \n",
    "\n",
    "#utilitée : permet d avoir une idee de la volatilitée de al var (si grosse vol largeur ++; si petite vol largueur --)\n",
    "\n",
    "#Sur la courbe il y a :\n",
    "#    le mean\n",
    "#    le mean + 2*std\n",
    "#    le mean - 2*std\n",
    "\n",
    "\n",
    "df['close 20day mean'] = df ['close'].rolling(20).mean()\n",
    "df['Upper'] = df['close 20day mean'] + ( 2 * df ['close'].rolling(20).std() )\n",
    "df['Lower'] = df['close 20day mean'] - ( 2 * df ['close'].rolling(20).std() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#petite astuce \n",
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resample fonction d agregation temporelle \n",
    "\n",
    "df.resample ( rule = 'BQ')\n",
    "# c est cool pour les tracer permet de grouper les données afin d avoir une vision sur l année ou sur le bq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rendement :\n",
    "\n",
    "#calcul de rendement simple : \n",
    "df['return'] = (  df['col'] /  df['col'].shift ( 1 ) ) - 1 \n",
    "#rendement cumulatif :\n",
    "df['return cumul' ] = ( 1 + df ['return' ] ).cumplod()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "definition \n",
    "\n",
    "- tendance : (3 possibilitées)\n",
    "a la hausse ,\n",
    "stationnaire,\n",
    "a la baisse ;\n",
    "la tendance est sur le mean\n",
    "\n",
    "- saisonalités : \n",
    "tendances qui se repete avec une regularité temporelle (la vente de pull en hiver)\n",
    "\n",
    "- le cycle :\n",
    "tendance avec des repetitions non definit\n",
    "\n",
    "\n",
    "la variance : les dispertions des val de y dans le temps (dispertion de l echantillion)\n",
    "\n",
    "la covariance : la vitesse de changement de la val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modele ETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------- Modele ETS : #error #tendance #saisonalités\n",
    "#decompose la cource en 3 composantes \n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "result = seasonall_decompose ( df[col] , model = x )  \n",
    "     #x = 'multiplicative'  (si courbe semble non linaire)   \n",
    "      ou = 'additive' (si courbe lineaire)\n",
    "\n",
    "fig = result.plot()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modele EWMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------- Modele EWMA : moyenne mobile pondere exponnentionellement\n",
    "\n",
    "#La methode rolling permet de calculer la moyenne mobile MA ou SMA (simple moyenne average) mais a plusieurs desavantages\n",
    "#La SMA est + utilisé pour  avoir une tendance. \n",
    "#La EWMA est bcp plus juste mathematiquement\n",
    "\n",
    "df['EWMA12'] = df['Thousands of Passengers'].ewm(span=12).mean()  #12mois = 1an la saisonalite\n",
    "df[['Thousands of Passengers','EWMA12']].plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELE ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------- #Modèle ARIMA  \n",
    "#(AR :auto regressif ; I : (integrated) diff du Modele ARMA car serie stationnaire ; MA : moyenne mobile)\n",
    "\n",
    "#les  ARIMA sont de 2 types:  saisonier et non saisonier\n",
    "\n",
    "\n",
    "# import \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "%matplotlib inline\n",
    "airpass = pd.read_csv('AirPassengersv2.csv', header=0, parse_dates=[0], index_col=0, squeeze=True)\n",
    "\n",
    "#analyse \n",
    "#type (airpass) #type\n",
    "airpass.plot()  #forme\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#1 ---------------------------------------------------------- Verifier que la série temporelle est stationnaire, \n",
    "#plusieurs façons :\n",
    "\n",
    "#methode 1 : analyse \n",
    "#Statistiques roulantes : Tracer la moyenne mobile et l’écart-type mobile. \n",
    "#La série temporelle est stationnaire si elle reste constante dans le temps \n",
    "#(à l’œil nu, regardez si les lignes sont droites et parallèles à l’axe des x)\n",
    "\n",
    "type (airpass) #type\n",
    "airpass.plot()  #forme\n",
    "airpass.rolling(20).mean().plot()  #non // a x\n",
    "airpass.rolling(20).std().plot()   #non // a x\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose   #decomposition ETS\n",
    "result = seasonal_decompose ( airpass, model = 'multiplicative' )\n",
    "fig = result.plot()\n",
    "\n",
    "\n",
    "\n",
    "#methode 2 : Test de Dickey-Fuller augmenté (ADF) \n",
    "#La série temporelle est considérée comme stationnaire si la valeur p est < 0.05 (hypothèse nulle)\n",
    "\n",
    "#Avec une fonction cree  :  \n",
    "adf_check(airpasslog) #la fonction est ecrite apres cette celule\n",
    "\n",
    "\n",
    "\n",
    "#Avec statsmodels directment : \n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "sm.tsa.stattools.adfuller(airpasslog_2)\n",
    "\n",
    "\n",
    "\n",
    "#Lorsque la pvalue est < 0.005 cela  signifie que la courbe est stationnaire\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#methode 3 : Cours datasientest\n",
    "\n",
    "airpasslog  = np.log( airpass)  #liniarisation de la courbe \n",
    "pd.plotting.autocorrelation_plot(airpasslog) #Affiche la fonction d'autocorrélation de la série\n",
    "\n",
    "#si retour du #2\n",
    "airpasslog_1 = airpasslog.diff().dropna()\n",
    "pd.plotting.autocorrelation_plot(airpasslog_1)\n",
    "\n",
    "\n",
    "\n",
    "#la conclusion est que si la courbe n est pas stabilisée il faut passer a #2 si courbe stabilisée on passe a #3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#2 ---------------------------------------------------------- Differentiation - Rendre la time serie stable (si necessaire)\n",
    "#plusieurs methodes\n",
    "\n",
    "#Methode 1 : avec Pandas (sur une time serie ) - differnetiation : \n",
    "df[diff1] = diff[col] - diff[col].shift (1 )  \n",
    "df[diff1].plot() # tracer la courbe diff1 pour avoir 1 apercu de la courbe si elle est stationnaire\n",
    "\n",
    "df[season_diff1] = diff[col] - diff[col].shift (12 )  #saisonalite\n",
    "df[season_diff1].plot() # tracer la courbe season_diff1 pour avoir 1 apercu de la courbe si elle est stationnaire\n",
    "\n",
    "#analyse #1 Test de Dickey-Fuller augmenté (ADF)\n",
    "\n",
    "\n",
    "\n",
    "#Methode 2 : avec Numpy (sur une time serie ) - differnetiation : \n",
    "airpasslog_1 = airpasslog.diff().dropna()  \n",
    "df[airpasslog_1].plot()\n",
    "\n",
    "airpasslog_2 = airpasslog_1.diff(periods = 12).dropna()   #saisonalite pour supprime les pics du a la saisonalite\n",
    "df[airpasslog_2].plot()\n",
    "\n",
    "#analyse #1 Test de Dickey-Fuller augmenté (ADF)\n",
    " \n",
    "    \n",
    "\n",
    "#conclusion : il faut absolument refaire le test Dickey-Fuller augmenté (ADF) sur la nouvelle colonne \n",
    "#afin de verifier que la pvalue est < 0.005 -> signifie que la courbe est stationnaire\n",
    "#avec dropna () pour suppr les lignes perdues\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#3 ----------------------------------------------------------  Choix des parametres  p, q et P, Q\n",
    "#Choix des parametres  p d q du Modele de la Moyenne Mobile Auto-Régressive Intégrée (ARIMA)\n",
    "\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_pacf, plot_acf\n",
    "\n",
    "plt.figure(figsize= (14,7))\n",
    "\n",
    "plt.subplot(121)\n",
    "#Fonction d’Auto-Corrélation (ACF) = PA = #p\n",
    "plot_acf(airpasslog_2, lags = 36, ax=plt.gca())   \n",
    "\n",
    "plt.subplot(122)\n",
    "#Fonction d’Auto-Corrélation Partielle (PACF) = MA = #q \n",
    "plot_pacf(airpasslog_2, lags = 36, ax=plt.gca())  \n",
    "\n",
    "plt.show()\n",
    "\n",
    "# p = au terme p-1 avant qu il s annule ( zone de non significativité )\n",
    "# q = au terme q-1 avant qu il s annule ( zone de non significativité )\n",
    "\n",
    "\n",
    "#4 ----------------------------------------------------------  Construction du modele \n",
    "\n",
    "#attention airpasslog de base et le nombre D et d correspond a l ordre de la differentiation\n",
    "#ARIMA = AR (auto regression P) ; I (integral D) ;MA (moyenne Q)\n",
    "\n",
    "model=sm.tsa.SARIMAX(airpasslog,order=(1,1,1),seasonal_order=(1,1,1,12))   #modele Arima pour seasonal order 12 : season de 12\n",
    "results=model.fit()       #fit\n",
    "print(results.summary())  #resume sur le modele entrainé\n",
    "\n",
    "#analyse du resumé\n",
    "#modèle(données, order=(p,d,q), seasonal_order = (P,D,Q,s))\n",
    "\n",
    "\n",
    "#5 ----------------------------------------------------------  Affinage\n",
    "# attention on affine le modele . \n",
    "# le changement d un param entraine le changement de tous les param, \n",
    "#pour etre sur il faut a chaque changement recreer un model et le Fit \n",
    "\n",
    "#pour les param p,q :\n",
    "#si regression liniaire suppr q\n",
    "#si Moving average suppr p\n",
    "\n",
    "\n",
    "#on recree le modele\n",
    "model=sm.tsa.SARIMAX(airpasslog,order=(1,1,1),seasonal_order=(1,1,1,12))   #modele Arima pour seasonal order 12 : season de 12\n",
    "results=model.fit()       #fit\n",
    "print(results.summary())  #resume sur le modele entrainé\n",
    "\n",
    "\n",
    "#pour les param P, Q :\n",
    "#suppr par la suite les P ou Q d on la pValue >0.05\n",
    "\n",
    "\n",
    "#on recree le modele avec les bon param\n",
    "model=sm.tsa.SARIMAX(airpasslog,order=(1,1,1),seasonal_order=(1,1,1,12))   #modele Arima pour seasonal order 12 : season de 12\n",
    "results=model.fit()       #fit\n",
    "print(results.summary())  #resume sur le modele entrainé\n",
    "\n",
    "#si c est ok la pvalue est proche ou egale a 0\n",
    "\n",
    "#6 ----------------------------------------------------------  bruits blancs\n",
    "\n",
    "#dans le resume : \n",
    "\n",
    "#Le test de Ljung-Box est un test de blancheur. \n",
    "#C'est un test statistique qui vise à rejeter ou non l'hypothèse  H0H0  : La résidu est un bruit blanc. \n",
    "#Ici on lit sur la ligne Prob(Q) que la p-valeur de ce test est de  0.650.65 , donc on ne rejette pas l'hypothèse.\n",
    "\n",
    "\n",
    "#Le test de Jarque-Bera est un test de normalité. \n",
    "#C'est un test statistique qui vise à rejeter ou non l'hypothèse  H0H0  : Le résidu suit une distribution normale. \n",
    "#Ici on lit sur la ligne Prob (JB) que la p-valeur du test est de  0.720.72 . On ne rejette donc pas l'hypothèse.\n",
    "\n",
    "\n",
    "\n",
    "#Conclusion\n",
    "#Le résidu vérfie les hypothèses que l'on a faites à priori.   \n",
    "#On peut donc conclure que le modèle  SARIMA(1,1,0)(0,1,1)12SARIMA⁡(1,1,0)(0,1,1)12  est satisfaisant.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#7 ----------------------------------------------------------  Prediction\n",
    "\n",
    "pred = np.exp(results.predict(132, 143))   #la ligne 132 a 143 = 12 = 1an\n",
    "airpasspred = pd.concat([airpass, pred])  #concat le reel et la predict\n",
    "plt.plot(airpasspred)    #plot\n",
    "plt.axvline(x='1960-01-01', color='red')   #train sur le plot entre le reel et la predict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#8 ---------------------------------------------------------- Verification Prediction / reel\n",
    "airpass_test = pd.read_csv('AirPassengers.csv', header=0, parse_dates=[0], index_col=0, squeeze=True).iloc[132:] #import des lignes du jeu\n",
    "\n",
    "plt.figure(figsize= (14,7))   #fig\n",
    "\n",
    "plt.subplot(121)   #supplot 1\n",
    "plt.plot(airpasspred);         #prediction\n",
    "plt.plot(airpass_test, '--')   #reel\n",
    "\n",
    "plt.subplot(122)   #supplot 2 : aux lignes 132 a 143\n",
    "plt.plot(airpasspred.iloc[132:]);  #prediction\n",
    "plt.plot(airpass_test, '--')      #reel\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#9 ----------------------------------------------------------  évaluer l'erreur du modele MAPE\n",
    "\n",
    "#Mean Average Prediction Error :  MAPE=1n∑t=1n||||Ytrue−YpredYtrue||||MAPE=1n∑t=1n|Ytrue−YpredYtrue|\n",
    "\n",
    "pred = airpasspred.iloc[132:]\n",
    "y_true, y_pred = np.array(airpass_test), np.array(pred)\n",
    "MAPE = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "print(\"Mean Absolute Prediction Error : %0.2f%%\"% MAPE)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fonction pour appliquer le Augmented Dickey-Fuller test sur une time serie\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Mémoriser dans une fonction pour une utilisation ultérieure !\n",
    "def adf_check(time_series):\n",
    "    \"\"\"\n",
    "    Passe une série temporelle, retourne le rapport ADF\n",
    "    \"\"\"\n",
    "    result = adfuller(time_series)\n",
    "    print('Augmented Dickey-Fuller test (DAF):')\n",
    "    labels = ['ADF Test Statistic','p-value','#Lags Used','Number of Observations Used']\n",
    "\n",
    "    for value,label in zip(result,labels):\n",
    "        print(label+' : '+str(value) )\n",
    "    \n",
    "    if result[1] <= 0.05:\n",
    "        print(\"Preuves solides contre l'hypothèse nulle, rejeter l'hypothèse nulle. Les données n'ont pas de racine unitaire et sont stationnaires\")\n",
    "    else:\n",
    "        print(\"Faible preuve contre l'hypothèse nulle, la série temporelle a une racine unitaire, ce qui indique qu'elle est non stationnaire \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Charger les bibliothèques pandas, numpy et statsmodels sous les noms pd, np et sm\n",
    "Charger le package matplolib.pyplot sous le nom plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargez les données contenues dans le fichier portland_v2.csv\n",
    "Attention au format de l'index et au type des données avant de passer aux questions suivantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "portland = pd.read_csv('portland_v2.csv',parse_dates=[0], index_col=0, squeeze=True)\n",
    "portland.head(2)\n",
    "portlandlog  = np.log( portland)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Représentez graphiquement les valeurs de la série"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portlandlog.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effectuez une décomposition saisonnière à l'aide de statsmodels\n",
    "Quelle est la période ? Privilégiera-t-on un modèle additif ou multiplicatif ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose   #decomposition ETS\n",
    "result = seasonal_decompose ( portlandlog, model = 'multiplicative' )\n",
    "fig = result.plot()\n",
    "#période = 12mois \n",
    "#le modele multiplicative est + adapté "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichez la fonction d'autocorrélation de la série"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.autocorrelation_plot(portlandlog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effectuez les opérations nécessaires pour estimer les paramètre  dd  et  DD  du modèle  SARIMASARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portland_1 = portlandlog.diff().dropna()  \n",
    "pd.plotting.autocorrelation_plot(portland_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #saisonalite :\n",
    "portland_2 = portland_1.diff(periods = 12).dropna()  \n",
    "pd.plotting.autocorrelation_plot(portland_2)  #les pics sont atteinués et reste proche de 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "sm.tsa.stattools.adfuller(portland_2)\n",
    "\n",
    "#la pvalue est <0.05 -> la courbe est stationnaire cela est confirmé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À l'aide des fonction ACF et PACF, estimez les autres paramètres probables du modele  SARIMASARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_pacf, plot_acf\n",
    "\n",
    "plt.figure(figsize= (14,7))\n",
    "\n",
    "plt.subplot(121)\n",
    "plot_acf(portland_2, lags = 36, ax=plt.gca())   \n",
    "\n",
    "plt.subplot(122)\n",
    "plot_pacf(portland_2, lags = 36, ax=plt.gca())  \n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimez à l'aide de la fonction SARIMAX le meilleur modèle possible pour cette série. Il se peut que tous les tests statistiques de normalité et de blancheur ne soient pas satisfaits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction d’Auto-Corrélation (ACF) = PA = #p s annule au rang 1  \n",
    "#Fonction d’Auto-Corrélation Partielle (PACF) = MA = #q s annule au rang 1\n",
    "\n",
    "model=sm.tsa.SARIMAX(portlandlog,order=(1,1,0),seasonal_order=(1,1,0,12))   \n",
    "results=model.fit()       #fit\n",
    "print(results.summary())  #resume sur le modele entrainé\n",
    "\n",
    "# bruits blanc\n",
    "#test de Ljung-Box val = 0.94 \n",
    "#test de Jarque-Bera val = 0.82 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effectuez une prédiction pour les 12 mois suivant la dernière mesure disponible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici\n",
    "portland.describe()\n",
    "\n",
    "pred = np.exp(results.predict(102, 113))   \n",
    "portlandpred = pd.concat([portland, pred])  \n",
    "plt.plot(portlandpred)    #\n",
    "plt.axvline(x='1981-06-01', color='red')   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lire les données présentes dans ce fichier\n",
    "Faire une représentation graphique des valeurs prédites et des valeurs réelles de la série"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-67e80899f6fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Insérez vote code ici\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mportland_8182\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'portland_8182.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0msqueeze\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Insérez vote code ici \n",
    "portland_8182 = pd.read_csv('portland_8182.csv', header=0, parse_dates=[0], index_col=0,  squeeze=True)\n",
    "\n",
    "\n",
    "plt.figure(figsize= (14,7))   \n",
    "\n",
    "plt.subplot(121)   \n",
    "plt.plot(portlandpred);         \n",
    "plt.plot(portland_8182, '--')   \n",
    "\n",
    "plt.subplot(122)   \n",
    "plt.plot(pred);  \n",
    "plt.plot(portland_8182, '--')     \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculez l'erreur moyenne relative de la prédiction.\n",
    "Que concluez-vous ? Sous-évaluation ou sur-évaluation des valeurs ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = portlandpred.iloc[102:] [0]\n",
    "\n",
    "y_true, y_pred = np.array(portland_8182), np.array(pred)\n",
    "\n",
    "MAPE = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "print(\"Mean Absolute Prediction Error : %0.2f%%\"% MAPE)\n",
    "\n",
    "#la temporalité semble bonne mais l amplitutude de la courbe predite est trop petite \n",
    "# Sous-évaluation\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
